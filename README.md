# 2022年中国高校计算机大赛-微信大数据挑战赛

[赛题详细信息点此](https://algo.weixin.qq.com/)

## 一、赛题摘要
**多模态短视频分类**
短视频数据中存在模态缺失、相关性弱、分类标签分布不均衡等问题。我们需要基于微信视频号短视频数据（文字、音频、视频三种模态信息）以及对应的分类标签标注，采用合理的机器学习技术对短视频进行分类预测。

初赛提供**百万量级的无标注数据**和**十万量级的有标注数据**；复赛阶段训练数据和初赛相同，主要区别是初赛阶段只提供视频抽帧特征，而复赛阶段提供视频抽帧原始图像。

P.S： 抽帧算法为 [Swin Transformer Tiny](https://zhuanlan.zhihu.com/p/361366090) 算法，复赛阶段会提供相应的算法，确保我们可以复现。

**数据格式**


![](https://tc.pengchen.tech/img/20220515204738.png)

**数据集**

![](https://tc.pengchen.tech/img/20220515204956.png)

**评估方法**
采用`F1 micro`和`F1 macro`的平均值。同时，分类体系包含一级分类和二级分类，在评测中会分别计算并取平均值。

最终指标为：

`(category1_f1_micro + category1_f1_macro + category2_f1_micro + category2_f1_macro) / 4`

```
评估代码可直接援引Baseline
```

## 二、算法框架与思路
### 1、数据处理与特征工程
数据中frames_feature字段维度高达768维，不经过处理直接放入模型不现实，初步设想采用如下的方法对特征进行降维
- [ ] LSTM
- [ ] 图神经网络
- [ ] 三维卷积神经网络
- [ ] 等等······
- [ ] 三维卷积神经网络不太行把，数据是四维的，一个是feature_frame,ocr,asr,以及文本信息，feature_frame和ocr是与时间相关的，其他的都与时间无关，用LSTM好像也不太合适

其次，`asr` `ocr` 字段含有大量中文文本信息，需要通过语义分析，提取有效信息，得到相应的清洗后的特征，初步设想：
- [ ] ？

### 2、分类器
采用`半监督学习`的方向，首先将`十万量级的有标注数据`切分为子训练集与子测试集，初步训练一个基础分类器，而后利用自训练对初步分类器进行迭代升级，具体步骤如下：

- ①用子训练集训练基础分类器；
- ②将分类器在**无标注数据**上进行预测，将预测结果中概率/相关性高于阈值的认作“伪标签”；*（可以通过概率为伪标签进行加权）*
- ③将带“伪标签”的数据与子训练集拼接，作为新的训练集重新训练分类器；
- ④将重训后的分类器在子测试集上进行测试，计算相应的F1值，评估分类器性能
重复②③④步，直到②中没有满足阈值的数据

十万量级的有标注数据就不需要做测试集了吧，做成有监督的学习模型，让他误差小于一定的阈值不就好了

## 三、还没想好！！！
